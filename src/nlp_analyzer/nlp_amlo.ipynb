{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMLO Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Users/fdmol/Desktop/AMLO-NLP/src/data/text_files/\"\n",
    "REGEX_PATTERNS = [\n",
    "    r\"copyright derechos reservados 2011-2020 - sitio oficial de andrés manuel lópez obrador\",\n",
    "    r\"versión estenográfica de la conferencia de prensa matutina del presidente de méxico, andrés manuel lópez obrador – amlo \\| \\d+/\\d+/\\d+\",\n",
    "    r\" descarga audio: \\d+-\\d+-\\d+ audio conferencia de prensa presidente de méxico palacio nacional,\",\n",
    "]\n",
    "\n",
    "STOPWORDS = [\n",
    "    \"el\",\n",
    "    \"ella\",\n",
    "    \"ellos\",\n",
    "    \"ellas\",\n",
    "    \"con\",\n",
    "    \"contra\",\n",
    "    \"como\",\n",
    "    \"de\",\n",
    "    \"por\",\n",
    "    \"para\",\n",
    "    \"a\",\n",
    "    \"ante\",\n",
    "    \"bajo\",\n",
    "    \"cabe\",\n",
    "    \"con\",\n",
    "    \"contra\",\n",
    "    \"de\",\n",
    "    \"desde\",\n",
    "    \"durante\",\n",
    "    \"en\",\n",
    "    \"entre\",\n",
    "    \"hacia\",\n",
    "    \"hasta\",\n",
    "    \"mediante\",\n",
    "    \"para\",\n",
    "    \"por\",\n",
    "    \"según\",\n",
    "    \"sin\",\n",
    "    \"so\",\n",
    "    \"sobre\",\n",
    "    \"tras\",\n",
    "    \"versus\",\n",
    "    \"vía\",\n",
    "    \"y\",\n",
    "    \"e\",\n",
    "    \"ni\",\n",
    "    \"o\",\n",
    "    \"u\",\n",
    "    \"pero\",\n",
    "    \"aunque\",\n",
    "    \"la\",\n",
    "    \"las\",\n",
    "    \"los\",\n",
    "    \"lo\",\n",
    "    \"un\",\n",
    "    \"una\",\n",
    "    \"unos\",\n",
    "    \"unas\",\n",
    "    \"al\",\n",
    "    \"del\",\n",
    "    \"lo\",\n",
    "    \"le\",\n",
    "    \"les\",\n",
    "    \"me\",\n",
    "    \"te\",\n",
    "    \"se\",\n",
    "    \"nos\",\n",
    "    \"os\",\n",
    "    \"les\",\n",
    "    \"le\",\n",
    "    \"me\",\n",
    "    \"te\",\n",
    "    \"se\",\n",
    "    \"nos\",\n",
    "    \"que\",\n",
    "    \"esta\",\n",
    "    \"este\",\n",
    "    \"estas\",\n",
    "    \"estos\",\n",
    "    \"porque\",\n",
    "    \"si\",\n",
    "    \"yo\",\n",
    "]\n",
    "\n",
    "\n",
    "PRESIDENT_REGEXES = [\n",
    "    r\"pregunta:.*\",\n",
    "    r\"interlocutor:.*\",\n",
    "    r\"intervención:.*\",\n",
    "    r\"interlocutora:.*\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextParser:\n",
    "    REGEX_PATTERNS = REGEX_PATTERNS\n",
    "    STOPWORDS = STOPWORDS\n",
    "    PRESIDENT_REGEXES = PRESIDENT_REGEXES\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.president_split = \"presidente andrés manuel lópez obrador:\"\n",
    "\n",
    "    def txt_to_list(self, filename):\n",
    "        \"\"\"\n",
    "        Add each line of a text file to a list\n",
    "        \"\"\"\n",
    "\n",
    "        file_path = os.path.join(self.path, filename)\n",
    "        lines = []\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip().split()\n",
    "                lines.append(line)\n",
    "\n",
    "        return lines\n",
    "\n",
    "    def file_to_string(self, filename):\n",
    "        \"\"\"\n",
    "        Add each line of a text file to a string\n",
    "        \"\"\"\n",
    "        text = \"\"\n",
    "        file_path = os.path.join(self.path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                text += line\n",
    "\n",
    "        text = text.strip()\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        for pattern in self.REGEX_PATTERNS:\n",
    "            text = re.sub(pattern, \"\", text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        \"\"\"\n",
    "        Removes predefined stopwords from a string\n",
    "        \"\"\"\n",
    "        text = text.split()\n",
    "        text = [word for word in text if word not in self.STOPWORDS]\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "\n",
    "    def get_presidents_dialogues(self, filename):\n",
    "        \"\"\"\n",
    "        Get the president's dialogues from a text file\n",
    "        \"\"\"\n",
    "        text = self.file_to_string(filename)\n",
    "        text = text.split(self.president_split)\n",
    "\n",
    "        # Apply regex to only get the president's dialogues\n",
    "        for regex in self.PRESIDENT_REGEXES:\n",
    "            text = [re.sub(regex, \"\", line) for line in text]\n",
    "\n",
    "        text = [line.strip() for line in text if line.strip() != \"\"]\n",
    "        text = text[1:]\n",
    "        return text\n",
    "\n",
    "    def save_all_presidents_dialogues(self, filename):\n",
    "        \"\"\"\n",
    "        Save the president's dialogues to a text file\n",
    "        \"\"\"\n",
    "\n",
    "        all_files = os.listdir(self.path)\n",
    "\n",
    "        for file in all_files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                text = self.get_presidents_dialogues(file)\n",
    "                file_path = os.path.join(self.path, file)\n",
    "                file_path = file_path.replace(\".txt\", \"_president_dialogues.txt\")\n",
    "                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    for line in text:\n",
    "                        f.write(line)\n",
    "                        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parser = TextParser(PATH)\n",
    "presidents_dialogues = text_parser.get_presidents_dialogues(\"202401025.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66124"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(presidents_dialogues)\n",
    "\n",
    "total_length = 0\n",
    "for dialogue in presidents_dialogues:\n",
    "    total_length += len(dialogue)\n",
    "\n",
    "total_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word     Score\n",
      "664          de  0.537529\n",
      "1944        que  0.377017\n",
      "856          el  0.353687\n",
      "1351         la  0.304227\n",
      "886          en  0.286496\n",
      "...         ...       ...\n",
      "214    aparatos  0.000933\n",
      "1140     guerra  0.000933\n",
      "215   apartados  0.000933\n",
      "216    apegados  0.000933\n",
      "2471      único  0.000933\n",
      "\n",
      "[2472 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use TF-IDF to find the most important words in the text\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "text = \" \".join(presidents_dialogues)\n",
    "\n",
    "# Create a TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Apply the vectorizer\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([text])\n",
    "\n",
    "# Print the result\n",
    "scores = tfidf_matrix.toarray()[0]\n",
    "words = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame with the result\n",
    "df = pd.DataFrame({\"Word\": words, \"Score\": scores})\n",
    "df.sort_values(\"Score\", ascending=False, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv(\"C:/Users/fdmol/Desktop/AMLO-NLP/src/data/word_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible models to use:\n",
    "\n",
    "Summarization:\n",
    "\n",
    "https://huggingface.co/mrm8488/bert2bert_shared-spanish-finetuned-summarization\n",
    "\n",
    "\n",
    "Sentiment Analysis:\n",
    "\n",
    "https://huggingface.co/finiteautomata/beto-sentiment-analysis\n",
    "\n",
    "\n",
    "Emotion Analysis:\n",
    "\n",
    "https://huggingface.co/finiteautomata/beto-emotion-analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jurados ciudadanos. bueno, pero tenemos que seguir avanzando en todo esto. y sí es importante iniciando el año recordar eso, que se necesita una reforma constitucional y que, para llevar a cabo una reforma constitucional se necesita contar con el apoyo de mayoría calificada; es decir, no sólo es la mayoría simple en las cámaras, 50 más uno, 50 por ciento más uno, sino se requieren dos terceras partes, a eso se le llama mayoría calificada. si no se tiene esa mayoría calificada, no se puede llevar a cabo ninguna reforma constitucional; tomar eso en cuenta, informarlo, porque ni modo que, a los manipuladores, a los que les conviene que siga este régimen de injusticias vayan a informarlo. ¿cuánto tiempo ha pasado, y quién sabía que para reformar la constitución se necesitaba de mayoría calificada? ¿quién sabía qué cosa es una mayoría calificada? ¿quién sabía cuántos votos de los 500 de la cámara de diputados son mayoría calificada? no son 251, sino son 374. jesús ramírez cuevas: trescientos treinta y cuatro.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents_dialogues[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¿ Cómo gestionar la libertad de cualquier persona, aun tratándose de delincuentes peligrosos, que hacen lo que les da la gana, se enriquecen?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt = \"mrm8488/bert2bert_shared-spanish-finetuned-summarization\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(ckpt)\n",
    "model = EncoderDecoderModel.from_pretrained(ckpt).to(device)\n",
    "\n",
    "\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer(\n",
    "        [text],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "text = presidents_dialogues[8]\n",
    "generate_summary(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 4.6140, -0.8551, -0.1549,  0.8921, -1.5799, -2.1146, -1.5987]],\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/beto-emotion-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"finiteautomata/beto-emotion-analysis\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
